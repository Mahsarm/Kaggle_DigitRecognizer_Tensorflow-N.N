{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "pixels_col = [col for col in df.columns if col != 'label']\n",
    "samples = df[pixels_col].values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px\">The output is an integer from 0-9. we use one hot encoding transformaton on a number to make a binary matrix of size 1*10 becauce the output value of the neural netwrok would be a probablity number between 0 -1 for each of the posisble digits. <br />\n",
    "example : number 3 --one_hot-encode-> [0,0,0,1,0,0,0,0,0,0,0] <br />\n",
    "the output probablity would be like: [0,0.07, 0.2,0.7,0.02,0,0,0,0,0.01 ]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_digits(x):\n",
    "    res = np.zeros((10,), dtype=float)\n",
    "    res[x] = 1.0\n",
    "    return(res)\n",
    "target = np.apply_along_axis(one_hot_digits, axis=1, arr=df[['label']])\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px\">Spliting the training data to test and train sets: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, X_test, train_target, y_test = train_test_split(samples, target, test_size=0.2, random_state=4242)\n",
    "train_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deep Neural Network Model:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;\">\n",
    "The model is a deep neural network with three hidden layers with the 500 nodes each. <br />\n",
    "layers weigh shape :  (N_samples X N_features)(input of the layer) * (weights of the layer)(N_features X N_outputs) => (outputof the layer)((N_samples X N_outputs) + biases(N_outputs X 1)) <br />\n",
    "biases shape: N_outputs X 1 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl1_no_nodes = 500\n",
    "hl2_no_nodes = 500\n",
    "hl3_no_nodes = 500\n",
    "n_classes = 10\n",
    "\n",
    "hidden_layer_one = {'weights': tf.Variable(tf.random_normal(shape = [784, hl1_no_nodes])),\n",
    "                    'biases': tf.Variable(tf.random_normal( shape = [hl1_no_nodes]))}\n",
    "    \n",
    "hidden_layer_two = {'weights': tf.Variable(tf.random_normal(shape = (hl1_no_nodes, hl2_no_nodes))),\n",
    "                    'biases': tf.Variable(tf.random_normal( shape = [hl2_no_nodes]))}\n",
    "    \n",
    "hidden_layer_three = {'weights': tf.Variable(tf.random_normal(shape = [hl2_no_nodes, hl3_no_nodes])),\n",
    "                      'biases': tf.Variable(tf.random_normal( shape = [hl3_no_nodes]))}\n",
    "    \n",
    "output_layer = {'weights': tf.Variable(tf.random_normal(shape = [hl3_no_nodes, n_classes])),\n",
    "                'biases': tf.Variable(tf.random_normal( shape = [n_classes]))}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px\">For speeding up the training, we train images in batches in every traning cycle (epoch), here we pick the size of each batch 100. <br/> \n",
    "x, y are tensorflow variables used for input and target</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px\">we apply a rectifier (rectifier linear unit:relu) which is an activation function to make the neurons in the hidden layers. <br />\n",
    "(output of the layer) = ((N_samples X N_outputs) + biases(N_outputs X 1))\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1_output = tf.add(tf.matmul(X, hidden_layer_one['weights']) , hidden_layer_one['biases'])\n",
    "layer1_output = tf.nn.relu(layer1_output)\n",
    "\n",
    "layer2_output = tf.add(tf.matmul(layer1_output , hidden_layer_two['weights']) , hidden_layer_two['biases'])\n",
    "layer2_output = tf.nn.relu(layer2_output)\n",
    "\n",
    "layer3_output = tf.add(tf.matmul(layer2_output, hidden_layer_three['weights']) , hidden_layer_three['biases'])\n",
    "layer3_output = tf.nn.relu(layer3_output)\n",
    "\n",
    "output = tf.matmul(layer3_output, output_layer['weights']) + output_layer['biases']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training the neural network:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px\">softmax is a logistic function () which predcits the probability of the classes (similar to sigmoid function)\n",
    "cross entropy: calcualtes the error or the difference between the predition and the target. <br />\n",
    "And reduce_mean (without specifiying the axis of cal) it returns the mean of a tensor elements and  a single value <br />\n",
    "and adamoptimizer minimizes the cost function</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = output\n",
    "#adding regulization:\n",
    "beta = 0.01\n",
    "regularizers =( tf.nn.l2_loss( hidden_layer_one['weights']) +  tf.nn.l2_loss(hidden_layer_two['weights']) + \n",
    " tf.nn.l2_loss( hidden_layer_three['weights'] + tf.nn.l2_loss( output_layer['weights'])) )            \n",
    "               \n",
    "cost = (tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y)) \n",
    "        + beta * regularizers)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px\">we extecute opration objects by running session: <br />\n",
    "prediction or output is tensor of probablity, for finding the accryacy \n",
    "we can find the index of max value of probablity for each sample by using argmax and which gives\n",
    "us the digit and compare it to the target value of the sample: <br />\n",
    "we use 100 cycle of feedforward to train the samples: epoch=100\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 1, 'completed out of', 100, 'loss:', 1689442509824.0, 'Accuracy:', 85.523808002471924)\n",
      "('Epoch', 2, 'completed out of', 100, 'loss:', 725722997888.0, 'Accuracy:', 88.047617673873901)\n",
      "('Epoch', 3, 'completed out of', 100, 'loss:', 366764497152.0, 'Accuracy:', 89.166665077209473)\n",
      "('Epoch', 4, 'completed out of', 100, 'loss:', 204903898720.0, 'Accuracy:', 89.702379703521729)\n",
      "('Epoch', 5, 'completed out of', 100, 'loss:', 122495508064.0, 'Accuracy:', 90.035712718963623)\n",
      "('Epoch', 6, 'completed out of', 100, 'loss:', 76852366736.0, 'Accuracy:', 90.321427583694458)\n",
      "('Epoch', 7, 'completed out of', 100, 'loss:', 49968487256.0, 'Accuracy:', 90.77380895614624)\n",
      "('Epoch', 8, 'completed out of', 100, 'loss:', 33380041192.0, 'Accuracy:', 90.976190567016602)\n",
      "('Epoch', 9, 'completed out of', 100, 'loss:', 22769527384.0, 'Accuracy:', 90.559524297714233)\n",
      "('Epoch', 10, 'completed out of', 100, 'loss:', 15787749192.0, 'Accuracy:', 90.416663885116577)\n",
      "('Epoch', 11, 'completed out of', 100, 'loss:', 11088923442.0, 'Accuracy:', 90.690475702285767)\n",
      "('Epoch', 12, 'completed out of', 100, 'loss:', 7868669774.0, 'Accuracy:', 91.166669130325317)\n",
      "('Epoch', 13, 'completed out of', 100, 'loss:', 5629205880.0, 'Accuracy:', 91.523808240890503)\n",
      "('Epoch', 14, 'completed out of', 100, 'loss:', 4053381658.0, 'Accuracy:', 91.464287042617798)\n",
      "('Epoch', 15, 'completed out of', 100, 'loss:', 2933717787.5, 'Accuracy:', 91.654759645462036)\n",
      "('Epoch', 16, 'completed out of', 100, 'loss:', 2132065460.5, 'Accuracy:', 91.583335399627686)\n",
      "('Epoch', 17, 'completed out of', 100, 'loss:', 1554430777.0, 'Accuracy:', 91.761904954910278)\n",
      "('Epoch', 18, 'completed out of', 100, 'loss:', 1136103670.5, 'Accuracy:', 91.785717010498047)\n",
      "('Epoch', 19, 'completed out of', 100, 'loss:', 831974082.75, 'Accuracy:', 91.880953311920166)\n",
      "('Epoch', 20, 'completed out of', 100, 'loss:', 610105704.75, 'Accuracy:', 92.202383279800415)\n",
      "('Epoch', 21, 'completed out of', 100, 'loss:', 447896072.25, 'Accuracy:', 91.940474510192871)\n",
      "('Epoch', 22, 'completed out of', 100, 'loss:', 329094897.4375, 'Accuracy:', 92.345237731933594)\n",
      "('Epoch', 23, 'completed out of', 100, 'loss:', 241889404.25, 'Accuracy:', 92.404758930206299)\n",
      "('Epoch', 24, 'completed out of', 100, 'loss:', 177859204.4375, 'Accuracy:', 93.071430921554565)\n",
      "('Epoch', 25, 'completed out of', 100, 'loss:', 130813304.96875, 'Accuracy:', 92.26190447807312)\n",
      "('Epoch', 26, 'completed out of', 100, 'loss:', 96284512.640625, 'Accuracy:', 92.773807048797607)\n",
      "('Epoch', 27, 'completed out of', 100, 'loss:', 70889595.515625, 'Accuracy:', 92.773807048797607)\n",
      "('Epoch', 28, 'completed out of', 100, 'loss:', 52242581.515625, 'Accuracy:', 92.988097667694092)\n",
      "('Epoch', 29, 'completed out of', 100, 'loss:', 38555246.4765625, 'Accuracy:', 93.142855167388916)\n",
      "('Epoch', 30, 'completed out of', 100, 'loss:', 28530907.9765625, 'Accuracy:', 93.238097429275513)\n",
      "('Epoch', 31, 'completed out of', 100, 'loss:', 21190262.96484375, 'Accuracy:', 93.345236778259277)\n",
      "('Epoch', 32, 'completed out of', 100, 'loss:', 15817852.20703125, 'Accuracy:', 93.547618389129639)\n",
      "('Epoch', 33, 'completed out of', 100, 'loss:', 11898089.982421875, 'Accuracy:', 93.416666984558105)\n",
      "('Epoch', 34, 'completed out of', 100, 'loss:', 9065082.974609375, 'Accuracy:', 93.095237016677856)\n",
      "('Epoch', 35, 'completed out of', 100, 'loss:', 6985489.15625, 'Accuracy:', 93.642854690551758)\n",
      "('Epoch', 36, 'completed out of', 100, 'loss:', 5489176.08984375, 'Accuracy:', 93.714284896850586)\n",
      "('Epoch', 37, 'completed out of', 100, 'loss:', 4390111.787109375, 'Accuracy:', 93.809521198272705)\n",
      "('Epoch', 38, 'completed out of', 100, 'loss:', 3583216.4873046875, 'Accuracy:', 94.119048118591309)\n",
      "('Epoch', 39, 'completed out of', 100, 'loss:', 2993068.5712890625, 'Accuracy:', 94.32142972946167)\n",
      "('Epoch', 40, 'completed out of', 100, 'loss:', 2612714.4453125, 'Accuracy:', 93.666666746139526)\n",
      "('Epoch', 41, 'completed out of', 100, 'loss:', 2298998.0390625, 'Accuracy:', 94.404762983322144)\n",
      "('Epoch', 42, 'completed out of', 100, 'loss:', 2027665.2109375, 'Accuracy:', 94.428569078445435)\n",
      "('Epoch', 43, 'completed out of', 100, 'loss:', 1859907.14453125, 'Accuracy:', 94.035714864730835)\n",
      "('Epoch', 44, 'completed out of', 100, 'loss:', 1724381.84375, 'Accuracy:', 94.559526443481445)\n",
      "('Epoch', 45, 'completed out of', 100, 'loss:', 1614728.4711914062, 'Accuracy:', 94.642859697341919)\n",
      "('Epoch', 46, 'completed out of', 100, 'loss:', 1540862.162109375, 'Accuracy:', 94.785714149475098)\n",
      "('Epoch', 47, 'completed out of', 100, 'loss:', 1454543.4345703125, 'Accuracy:', 94.869047403335571)\n",
      "('Epoch', 48, 'completed out of', 100, 'loss:', 1401201.3500976562, 'Accuracy:', 94.857144355773926)\n",
      "('Epoch', 49, 'completed out of', 100, 'loss:', 1333780.9865722656, 'Accuracy:', 95.059525966644287)\n",
      "('Epoch', 50, 'completed out of', 100, 'loss:', 1279170.630859375, 'Accuracy:', 94.952380657196045)\n",
      "('Epoch', 51, 'completed out of', 100, 'loss:', 1228210.3972167969, 'Accuracy:', 94.559526443481445)\n",
      "('Epoch', 52, 'completed out of', 100, 'loss:', 1199320.3588867188, 'Accuracy:', 94.833332300186157)\n",
      "('Epoch', 53, 'completed out of', 100, 'loss:', 1168762.6213378906, 'Accuracy:', 94.809526205062866)\n",
      "('Epoch', 54, 'completed out of', 100, 'loss:', 1131271.1467285156, 'Accuracy:', 95.166665315628052)\n",
      "('Epoch', 55, 'completed out of', 100, 'loss:', 1097223.7292480469, 'Accuracy:', 95.380949974060059)\n",
      "('Epoch', 56, 'completed out of', 100, 'loss:', 1073060.1916503906, 'Accuracy:', 95.166665315628052)\n",
      "('Epoch', 57, 'completed out of', 100, 'loss:', 1050900.9016113281, 'Accuracy:', 94.880950450897217)\n",
      "('Epoch', 58, 'completed out of', 100, 'loss:', 1022135.2092285156, 'Accuracy:', 95.107144117355347)\n",
      "('Epoch', 59, 'completed out of', 100, 'loss:', 1006512.1381835938, 'Accuracy:', 95.035713911056519)\n",
      "('Epoch', 60, 'completed out of', 100, 'loss:', 985253.25903320312, 'Accuracy:', 95.476192235946655)\n",
      "('Epoch', 61, 'completed out of', 100, 'loss:', 969543.00317382812, 'Accuracy:', 95.369046926498413)\n",
      "('Epoch', 62, 'completed out of', 100, 'loss:', 952268.17041015625, 'Accuracy:', 95.369046926498413)\n",
      "('Epoch', 63, 'completed out of', 100, 'loss:', 928963.59155273438, 'Accuracy:', 95.392858982086182)\n",
      "('Epoch', 64, 'completed out of', 100, 'loss:', 913735.2880859375, 'Accuracy:', 95.404762029647827)\n",
      "('Epoch', 65, 'completed out of', 100, 'loss:', 896059.36083984375, 'Accuracy:', 94.988095760345459)\n",
      "('Epoch', 66, 'completed out of', 100, 'loss:', 887782.310546875, 'Accuracy:', 94.738095998764038)\n",
      "('Epoch', 67, 'completed out of', 100, 'loss:', 870828.23217773438, 'Accuracy:', 95.428574085235596)\n",
      "('Epoch', 68, 'completed out of', 100, 'loss:', 860530.365234375, 'Accuracy:', 95.285713672637939)\n",
      "('Epoch', 69, 'completed out of', 100, 'loss:', 845540.93774414062, 'Accuracy:', 95.642858743667603)\n",
      "('Epoch', 70, 'completed out of', 100, 'loss:', 828032.90844726562, 'Accuracy:', 95.452380180358887)\n",
      "('Epoch', 71, 'completed out of', 100, 'loss:', 821461.94702148438, 'Accuracy:', 95.488095283508301)\n",
      "('Epoch', 72, 'completed out of', 100, 'loss:', 811076.091796875, 'Accuracy:', 95.19047737121582)\n",
      "('Epoch', 73, 'completed out of', 100, 'loss:', 801892.32275390625, 'Accuracy:', 95.214283466339111)\n",
      "('Epoch', 74, 'completed out of', 100, 'loss:', 789915.38720703125, 'Accuracy:', 95.083332061767578)\n",
      "('Epoch', 75, 'completed out of', 100, 'loss:', 780306.95434570312, 'Accuracy:', 95.571428537368774)\n",
      "('Epoch', 76, 'completed out of', 100, 'loss:', 769895.021484375, 'Accuracy:', 95.619046688079834)\n",
      "('Epoch', 77, 'completed out of', 100, 'loss:', 755588.99365234375, 'Accuracy:', 95.214283466339111)\n",
      "('Epoch', 78, 'completed out of', 100, 'loss:', 746663.51123046875, 'Accuracy:', 95.369046926498413)\n",
      "('Epoch', 79, 'completed out of', 100, 'loss:', 738836.25830078125, 'Accuracy:', 95.476192235946655)\n",
      "('Epoch', 80, 'completed out of', 100, 'loss:', 726423.94921875, 'Accuracy:', 95.178574323654175)\n",
      "('Epoch', 81, 'completed out of', 100, 'loss:', 724603.8681640625, 'Accuracy:', 95.690476894378662)\n",
      "('Epoch', 82, 'completed out of', 100, 'loss:', 705214.037109375, 'Accuracy:', 95.53571343421936)\n",
      "('Epoch', 83, 'completed out of', 100, 'loss:', 694167.25012207031, 'Accuracy:', 95.702379941940308)\n",
      "('Epoch', 84, 'completed out of', 100, 'loss:', 689525.57922363281, 'Accuracy:', 95.666664838790894)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 85, 'completed out of', 100, 'loss:', 679504.73205566406, 'Accuracy:', 95.416665077209473)\n",
      "('Epoch', 86, 'completed out of', 100, 'loss:', 670164.240234375, 'Accuracy:', 95.726191997528076)\n",
      "('Epoch', 87, 'completed out of', 100, 'loss:', 664183.91003417969, 'Accuracy:', 95.261907577514648)\n",
      "('Epoch', 88, 'completed out of', 100, 'loss:', 650240.58764648438, 'Accuracy:', 95.714282989501953)\n",
      "('Epoch', 89, 'completed out of', 100, 'loss:', 641286.64453125, 'Accuracy:', 95.773810148239136)\n",
      "('Epoch', 90, 'completed out of', 100, 'loss:', 635143.8896484375, 'Accuracy:', 95.369046926498413)\n",
      "('Epoch', 91, 'completed out of', 100, 'loss:', 626909.142578125, 'Accuracy:', 96.119046211242676)\n",
      "('Epoch', 92, 'completed out of', 100, 'loss:', 615854.22595214844, 'Accuracy:', 95.964282751083374)\n",
      "('Epoch', 93, 'completed out of', 100, 'loss:', 610519.78405761719, 'Accuracy:', 95.345240831375122)\n",
      "('Epoch', 94, 'completed out of', 100, 'loss:', 603387.1357421875, 'Accuracy:', 95.714282989501953)\n",
      "('Epoch', 95, 'completed out of', 100, 'loss:', 590052.92529296875, 'Accuracy:', 96.238094568252563)\n",
      "('Epoch', 96, 'completed out of', 100, 'loss:', 583108.29406738281, 'Accuracy:', 95.904761552810669)\n",
      "('Epoch', 97, 'completed out of', 100, 'loss:', 575015.31481933594, 'Accuracy:', 95.678573846817017)\n",
      "('Epoch', 98, 'completed out of', 100, 'loss:', 565793.48278808594, 'Accuracy:', 95.773810148239136)\n",
      "('Epoch', 99, 'completed out of', 100, 'loss:', 559352.76611328125, 'Accuracy:', 95.76190710067749)\n",
      "('Epoch', 100, 'completed out of', 100, 'loss:', 548867.03344726562, 'Accuracy:', 95.380949974060059)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "epochs = 100\n",
    "is_correct = tf.equal(tf.argmax(prediction,1) , tf.argmax(y,1))    \n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "#accuracy_test_b0 = []\n",
    "#accuracy_train_b0 = []\n",
    "# accuracy_test_b0_01 = []\n",
    "# accuracy_train_b0_01 = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_loss = 0\n",
    "        X_train, y_train = shuffle(train_samples, train_target, random_state=45)\n",
    "        for _ in range(train_samples.shape[0]/batch_size):\n",
    "           \n",
    "            train_feed_dict = {X: X_train[(_*batch_size):((_+1)*batch_size)],\n",
    "                         y:y_train[(_*batch_size):((_+1)*batch_size)]}\n",
    "            _, c = sess.run([optimizer, cost], train_feed_dict)\n",
    "            epoch_loss += c\n",
    "        test_feed_dict = {X: X_test, y:y_test}\n",
    "        accuracy_test = 100*sess.run(accuracy,feed_dict=test_feed_dict)\n",
    "        #accuracy_train = sess.run(accuracy*100,feed_dict=train_feed_dict)\n",
    "        #accuracy_test_b0.append(accuracy_test)\n",
    "        #accuracy_train_b0.append(accuracy_train)\n",
    "        print('Epoch', epoch, 'completed out of', epochs, 'loss:', epoch_loss, 'Accuracy:', accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy_df= pd.DataFrame({\"train accuracy(beta=0)\": accuracy_train_b0,\n",
    "#                            \"test accuracy(beta=0.0)\": accuracy_test_b0,\n",
    "#                            \"train accuracy(beta=0.01)\": accuracy_train_b0_01,\n",
    "#                            \"test accuracy(beta=0.01)\": accuracy_test_b0_01 }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy_df.to_csv('accuracy(beta=0,0.01,epoch=100).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Accuracy_data = pd.read_csv('accuracy(beta=0,0.01,epoch=100).csv')\n",
    "Accuracy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
